# ğŸ“˜ Regulation-Aware RAG System with Governance Agent (with Memory)

This project implements a **Regulation-Aware Retrieval-Augmented Generation (RAG) System** combined with a **Compliance Governance Agent** using Langchain and LangGraph.
It evaluates whether a proposed **ACTION** complies with an organizationâ€™s **policies**, explains the reasoning, and suggests changes if necessary.

The system also includes an **AI Memory Module**, enabling context-aware decisions based on past actions.

# âœ¨ Key Features

### ğŸ” **1. Policy Retrieval (RAG)**

* Loads policy documents
* Splits into chunks
* Embeds using `sentence-transformers/all-MiniLM-L6-v2`
* Builds or loads FAISS index
* Retrieves top-k relevant policy sections

### ğŸ§  **2. Governance Evaluation**

* Evaluates ACTION + CONTEXT using:

  * Retrieved policies
  * Past decisions (memory)
    
* Enforces strict JSON schema:

```
{
  "decision": "Allowed | Not Allowed | Needs Review",
  "reason": "...",
  "suggested_changes": ["..."],
  "references": ["Policy Name Section X.Y"]
}
```

### ğŸ’¾ **3. Memory Module**

Stores:

* Action
* Context
* Final LLM decision
  And feeds past 8 decisions back into the LLM.

### ğŸ—ï¸ **4. LangGraph Workflow**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RETRIEVE â”‚ â†’â†’  â”‚  EVALUATE  â”‚ â†’â†’  â”‚ MEMORY â”‚ â†’â†’ END
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ¤– **5. Full Local LLM Support**

* Loads any HuggingFace causal LM
* If loading fails â†’ uses **dummy fallback LLM** with JSON output
* Ensures uninterrupted workflow

---

# ğŸ“‚ Project File Structure

```
ASSIGNMENT_1/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ data_policy.txt             # Policy document used for RAG
â”‚   â”œâ”€â”€ fais_index_policy/          # Auto-generated FAISS index
â”‚  
â”‚â”€â”€ fais_index_policy/              # Auto-generated FAISS index
â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ memory_node.py              # Memory archiving node
â”‚   â””â”€â”€ state.py                    # AgentState Pydantic model
â”‚
â”œâ”€â”€ model/                          # Local model
â”‚
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ sample1_output/
â”‚   â”œâ”€â”€ sample2_output/
â”‚   â””â”€â”€ sample_input.txt
â”‚
â”œâ”€â”€ retriever.py                    # PolicyRetriever + LangGraph RAG node
â”œâ”€â”€ governance_agent.py             # EvaluateActionNode (LLM evaluator)
â”œâ”€â”€ graph.py                        # LangGraph workflow builder
â”œâ”€â”€ main.py                         # CLI runner for the workflow
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md   
â””â”€â”€ .gitignore
```

---

# âš™ï¸ How the System Works (Step-by-Step)

## **Step 1 â€” RETRIEVE**

`PolicyRetrieverNode.run()`

* Builds/loads FAISS index
* Retrieves the most relevant policy chunks
* Adds them to `state.retrieved_policies`

Logs:

```
ğŸ” Step 1: RETRIEVE - Searching for relevant policies...
Success: Retrieved 4 policy document(s).
```

---

## **Step 2 â€” EVALUATE**

`EvaluateActionNode.run()`

* Prepares the final prompt:

  * ACTION
  * CONTEXT
  * RETRIEVED POLICIES
  * PAST DECISIONS (memory)
  * JSON schema instructions
* Sends prompt to the LLM
* Parses output using `PydanticOutputParser`

Logs:

```
ğŸ§  Step 2: EVALUATE - Running LLM for decision...
LLM Output Received (raw): { "decision": "Not Allowed", ... }
Decision: 'Not Allowed'
```

---

## **Step 3 â€” MEMORY**

`memory_node()`
Stores:

```json
{
  "action": "...",
  "context": "...",
  "result": {...}
}
```

Logs:

```
ğŸ’¾ Step 3: MEMORY - Archiving current decision...
Action 'Store user data...' archived.
Total decisions in memory: 1
```

## **Step 4 â€” OUTPUT**

`main.py` prints a clean JSON output:

```
===== GOVERNANCE DECISION (Clean Output) =====
{
  "decision": "Not Allowed",
  "reason": "...",
  "suggested_changes": [...],
  "references": [...]
}
=============================================
```

# ğŸš€ Running the Agent

```
CREATE ENV
ACTIVATE IT

```

## **1. Install Requirements**

```
pip install -r requirements.txt
```

## **2. Check model is available or not in model folder *

```
If no model is present â†’ download it.
```

## **3. Run**

```
python main.py
```

# ğŸ“ Input Format

You can enter:

### **Option 1: Raw JSON**

```
{
  "action": "Store user data on an analytics server",
  "context": "The team wants fast reporting"
}
```

Press enter twice to submit.

### **Option 2: Plain Action Text**


# ğŸ§¾ Sample Output

```
{
  "decision": "Not Allowed",
  "reason": "Storing user data on an external analytics server violates Data Storage Policy Section 1.1.",
  "suggested_changes": [
    "Obtain explicit approval from the Data Protection Officer.",
    "Encrypt user data before transmission."
  ],
  "references": [
    "Data Storage Policy Section 1.1"
  ]
}
```

# ğŸ§  Memory Example

After multiple queries:

```
PAST DECISIONS:
Past 1: action='Store data Externally...' | decision=Not Allowed
Past 2: action='Share logs...' | decision=Needs Review
...
```

The LLM now sees **historical behavior**, enabling more consistent governance decisions.

# ğŸ› ï¸ Developer Notes

### ğŸ”§ **FAISS index rebuilds automatically**

* When `data_policy.txt` is modified
* When index folder missing
* When timestamp mismatch detected

### ğŸ§¹ **Output is always clean JSON**
